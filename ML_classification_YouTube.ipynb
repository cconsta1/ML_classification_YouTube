{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwdZIikJo8Ol0p5yFHvi32",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cconsta1/ML_classification_YouTube/blob/main/ML_classification_YouTube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colab Tutorial: Basic ML Classification with scikit-learn, PyTorch, and a Dash web app\n",
        "\n",
        "This Colab notebook demonstrates a full, workflow you can use to build ML classification models, and deploy them as web apps:\n",
        "- Generate synthetic data (make_classification) with 10000 points, 4 features and 2 classes (Yes / No).\n",
        "- Train and evaluate XGBoost, Random Forest, Logistic Regression, scikit-learn MLPClassifier.\n",
        "- Implement an equivalent deep but simple neural network in PyTorch; train and evaluate it.\n",
        "- Compare models, choose the two best, save them.\n",
        "- Build an interactive web app (Dash + JupyterDash) that runs inside Colab and accepts 4 feature inputs and returns a prediction from either of the chosen models.\n"
      ],
      "metadata": {
        "id": "tCIuEFSLcakU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup: Install packages and imports\n",
        "\n",
        "\n",
        "- We'll install the required packages jupyter-dash, everything else is pre-installed.\n",
        "- Then we import common libraries and set random seeds for reproducibility.\n",
        "- Running this cell prepares the Colab runtime with the libraries used later."
      ],
      "metadata": {
        "id": "6PDxgrQ8c8kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages (run once in Colab)\n",
        "!pip install -q jupyter-dash\n",
        "\n",
        "# Imports and seeds\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import joblib\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import xgboost as xgb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# For Dash app later\n",
        "from jupyter_dash import JupyterDash\n",
        "import dash\n",
        "from dash import dcc, html, Input, Output, State\n",
        "import plotly.express as px\n",
        "\n",
        "# Reproducibility\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)\n",
        "torch.manual_seed(RANDOM_STATE)\n"
      ],
      "metadata": {
        "id": "58euL4EgdGRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data generation: make_classification\n",
        "\n",
        "Explanation:\n",
        "- We generate a binary classification dataset with 10000 samples, 4 features, 4 informative features, 0 redundant, 2 classes.\n",
        "- We map labels 0/1 to \"No\"/\"Yes\" for display purposes, but models will train on numerical labels.\n",
        "- We'll split into train, validation and test sets and scale features using StandardScaler (save the scaler for deployment)."
      ],
      "metadata": {
        "id": "NPbLekm6dOET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Generate data\n",
        "X, y = make_classification(\n",
        "    n_samples=10000,\n",
        "    n_features=4,\n",
        "    n_informative=4,\n",
        "    n_redundant=0,\n",
        "    n_repeated=0,\n",
        "    n_classes=2,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Map to DataFrame for easier display if needed\n",
        "df = pd.DataFrame(X, columns=[f\"f{i+1}\" for i in range(X.shape[1])])\n",
        "df['target'] = y\n",
        "\n",
        "# Train / test split (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=RANDOM_STATE, stratify=y)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Save scaler for deployment\n",
        "joblib.dump(scaler, \"scaler.joblib\")\n",
        "\n",
        "print(\"Shapes:\", X_train.shape, X_test.shape)\n",
        "print(\"Class distribution (train):\", np.bincount(y_train))\n"
      ],
      "metadata": {
        "id": "Ejk1B2q7dec0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "lSxUK4zg4jpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "429a243c"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr_matrix = df[[\"f1\",\"f2\",\"f3\",\"f4\"]].corr()\n",
        "\n",
        "# Visualize the correlation matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix of Features')\n",
        "plt.show()\n",
        "\n",
        "# You can also identify highly correlated pairs programmatically\n",
        "# Let's find pairs with absolute correlation greater than a threshold (e.g., 0.8)\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "to_drop = [column for column in upper.columns if any(upper[column].abs() > 0.8)]\n",
        "\n",
        "print(\"\\nFeatures to potentially drop due to high correlation (threshold > 0.8):\")\n",
        "print(to_drop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(X_train_scaled).describe()"
      ],
      "metadata": {
        "id": "R0oO8WaL6-cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Evaluation utilities\n",
        "\n",
        "Explanation:\n",
        "- Define a helper function to compute and print consistent evaluation metrics (accuracy, precision, recall, f1, ROC AUC).\n",
        "- We'll use this for every model so the comparison is fair and standardized."
      ],
      "metadata": {
        "id": "wZpVl6GEet-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model_name, y_true, y_pred, y_proba=None):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    roc = np.nan\n",
        "    if y_proba is not None:\n",
        "        try:\n",
        "            # Expect y_proba shape (n_samples, 2) or (n_samples,) for positives\n",
        "            if y_proba.ndim == 2 and y_proba.shape[1] == 2:\n",
        "                roc = roc_auc_score(y_true, y_proba[:,1])\n",
        "            else:\n",
        "                roc = roc_auc_score(y_true, y_proba.reshape(-1))\n",
        "        except Exception:\n",
        "            roc = np.nan\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\" Accuracy: {acc:.4f}\")\n",
        "    print(f\" Precision: {prec:.4f}\")\n",
        "    print(f\" Recall: {rec:.4f}\")\n",
        "    print(f\" F1: {f1:.4f}\")\n",
        "    print(f\" ROC AUC: {roc:.4f}\")\n",
        "    print(\"Classification report:\")\n",
        "    print(classification_report(y_true, y_pred, zero_division=0))\n",
        "    return {\"model\": model_name, \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"roc_auc\": roc}"
      ],
      "metadata": {
        "id": "yb9JYPFie0S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train classical models: Logistic Regression, Random Forest, XGBoost (evaluate on test)\n",
        "\n",
        "Explanation:\n",
        "- Train each classical model on the training set and evaluate on the held-out test set (80/20 split).\n",
        "- Save the trained models for the web app.\n"
      ],
      "metadata": {
        "id": "u3y83dDQe276"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "lr = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "y_test_pred_lr = lr.predict(X_test_scaled)\n",
        "y_test_proba_lr = lr.predict_proba(X_test_scaled)\n",
        "res_lr = evaluate_model(\"LogisticRegression\", y_test, y_test_pred_lr, y_test_proba_lr)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1)\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "y_test_pred_rf = rf.predict(X_test_scaled)\n",
        "y_test_proba_rf = rf.predict_proba(X_test_scaled)\n",
        "res_rf = evaluate_model(\"RandomForest\", y_test, y_test_pred_rf, y_test_proba_rf)\n",
        "\n",
        "# XGBoost\n",
        "xgb_clf = xgb.XGBClassifier(eval_metric='logloss', random_state=RANDOM_STATE, n_estimators=200)\n",
        "xgb_clf.fit(X_train_scaled, y_train)\n",
        "y_test_pred_xgb = xgb_clf.predict(X_test_scaled)\n",
        "y_test_proba_xgb = xgb_clf.predict_proba(X_test_scaled)\n",
        "res_xgb = evaluate_model(\"XGBoost\", y_test, y_test_pred_xgb, y_test_proba_xgb)\n",
        "\n",
        "# Save these models (we will possibly use them later)\n",
        "joblib.dump(lr, \"logistic_regression.joblib\")\n",
        "joblib.dump(rf, \"random_forest.joblib\")\n",
        "joblib.dump(xgb_clf, \"xgboost.joblib\")"
      ],
      "metadata": {
        "id": "Pq3JIGSke8dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. scikit-learn MLPClassifier (train on train, evaluate on test)\n",
        "\n",
        "Explanation:\n",
        "- Train an MLPClassifier with hidden layers (128,64,32) and evaluate on the test set."
      ],
      "metadata": {
        "id": "r6Ajzr7ffLQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes=(128,64,32), activation='relu', solver='adam', max_iter=200, random_state=RANDOM_STATE)\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "y_test_pred_mlp = mlp.predict(X_test_scaled)\n",
        "y_test_proba_mlp = mlp.predict_proba(X_test_scaled)\n",
        "res_mlp = evaluate_model(\"Sklearn-MLP\", y_test, y_test_pred_mlp, y_test_proba_mlp)\n",
        "\n",
        "joblib.dump(mlp, \"sklearn_mlp.joblib\")"
      ],
      "metadata": {
        "id": "Qz0_BUj7fOBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. PyTorch network: design, training loop, and evaluation (train on train, evaluate on test)\n",
        "\n",
        "Explanation:\n",
        "- Implement a PyTorch network with capacity similar to scikit's MLP.\n",
        "- Train on the training set and evaluate on the test set (used for final comparison and app inclusion).\n"
      ],
      "metadata": {
        "id": "HSD-YysLfaRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define PyTorch model\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, input_dim=4):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)  # single logit for binary classification\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        # Return logits shaped (batch,) to keep compatibility with BCEWithLogitsLoss\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "# Prepare datasets and loaders\n",
        "batch_size = 128\n",
        "train_dataset = TensorDataset(torch.tensor(X_train_scaled, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
        "test_dataset = TensorDataset(torch.tensor(X_test_scaled, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleNet(input_dim=X_train_scaled.shape[1]).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Training loop (evaluate on test each epoch, keep best by test loss)\n",
        "n_epochs = 100\n",
        "best_test_loss = float('inf')\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "    avg_train_loss = total_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Test evaluation\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    preds = []\n",
        "    probs = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in test_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            test_loss += loss.item() * xb.size(0)\n",
        "\n",
        "            prob = torch.sigmoid(logits).cpu().numpy().reshape(-1, 1)\n",
        "            probs.append(prob)\n",
        "            preds.append((prob >= 0.5).astype(int))\n",
        "    avg_test_loss = test_loss / len(test_loader.dataset)\n",
        "    probs_np = np.vstack(probs)\n",
        "    preds_np = np.vstack(preds).flatten()\n",
        "    test_acc = accuracy_score(y_test, preds_np)\n",
        "    print(f\"Epoch {epoch}/{n_epochs} - train_loss: {avg_train_loss:.4f}, test_loss: {avg_test_loss:.4f}, test_acc: {test_acc:.4f}\")\n",
        "    if avg_test_loss < best_test_loss:\n",
        "        best_test_loss = avg_test_loss\n",
        "        torch.save(model.state_dict(), \"pytorch_net_best.pth\")\n",
        "\n",
        "# Load best model and evaluate on test\n",
        "best_model = SimpleNet(input_dim=X_train_scaled.shape[1]).to(device)\n",
        "best_model.load_state_dict(torch.load(\"pytorch_net_best.pth\", map_location=device))\n",
        "best_model.eval()\n",
        "with torch.no_grad():\n",
        "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
        "    logits = best_model(X_test_tensor)\n",
        "    probs_test = torch.sigmoid(logits).cpu().numpy().reshape(-1, 1)\n",
        "    preds_test = (probs_test >= 0.5).astype(int).reshape(-1)\n",
        "res_torch = evaluate_model(\"PyTorch-Net\", y_test, preds_test, y_proba=np.hstack([1-probs_test, probs_test]))"
      ],
      "metadata": {
        "id": "q6Kt7Ttgfn8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Compare models on the test set and pick top two (by accuracy)\n",
        "\n",
        "Explanation:\n",
        "- Collect test-set metrics for all trained models and choose the two best by accuracy.\n",
        "- We'll include those two plus the PyTorch model in the web app."
      ],
      "metadata": {
        "id": "d2oPibFdgGKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect results (we computed res_* earlier on test set)\n",
        "results = [res_lr, res_rf, res_xgb, res_mlp, res_torch]\n",
        "results_df = pd.DataFrame(results).sort_values(by=['accuracy', 'f1', 'roc_auc'], ascending=False)\n",
        "results_df.reset_index(drop=True, inplace=True)\n",
        "results_df\n",
        "\n",
        "# Choose top 2 by accuracy\n",
        "top2 = results_df.iloc[:2]['model'].tolist()\n",
        "print(\"Top 2 selected models (by accuracy):\", top2)\n"
      ],
      "metadata": {
        "id": "DV3CMX02gMKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Save models and artifacts (confirm)\n",
        "\n",
        "Explanation:\n",
        "- We already saved scikit models and the PyTorch state_dict. Confirm saved files exist."
      ],
      "metadata": {
        "id": "WSE1hMF6gS3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Save check (skipped saving repeated objects if already present)\n",
        "joblib.dump(lr, \"logistic_regression.joblib\")\n",
        "joblib.dump(rf, \"random_forest.joblib\")\n",
        "joblib.dump(xgb_clf, \"xgboost.joblib\")\n",
        "joblib.dump(mlp, \"sklearn_mlp.joblib\")\n",
        "# pytorch saved above as pytorch_net_best.pth\n",
        "\n",
        "for fn in [\"scaler.joblib\", \"logistic_regression.joblib\", \"random_forest.joblib\", \"xgboost.joblib\", \"sklearn_mlp.joblib\", \"pytorch_net_best.pth\"]:\n",
        "    print(fn, \"exists?\", os.path.exists(fn))"
      ],
      "metadata": {
        "id": "55sbTEXugYVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Build a Dash web app in Colab with a vintage-modern theme\n",
        "\n",
        "Explanation:\n",
        "- The app will contain:\n",
        "  - The two best scikit models (selected by accuracy) and the PyTorch model.\n",
        "  - Four numeric inputs for the features.\n",
        "  - A dropdown to choose among these three models.\n",
        "  - A vintage color palette with a modern font ('Montserrat').\n",
        "\n",
        "Notes:\n",
        "- The app is launched inside Colab as an iframe.\n",
        "- The UI styling is lightweight and inline so it works in Colab without extra files.\n"
      ],
      "metadata": {
        "id": "_dmTa-hIgcth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load artifacts needed for the app and create the subset of models to include: top2 + PyTorch\n",
        "scaler = joblib.load(\"scaler.joblib\")\n",
        "\n",
        "# Load saved scikit models\n",
        "models_all = {}\n",
        "if os.path.exists(\"logistic_regression.joblib\"):\n",
        "    models_all[\"LogisticRegression\"] = joblib.load(\"logistic_regression.joblib\")\n",
        "if os.path.exists(\"random_forest.joblib\"):\n",
        "    models_all[\"RandomForest\"] = joblib.load(\"random_forest.joblib\")\n",
        "if os.path.exists(\"xgboost.joblib\"):\n",
        "    models_all[\"XGBoost\"] = joblib.load(\"xgboost.joblib\")\n",
        "if os.path.exists(\"sklearn_mlp.joblib\"):\n",
        "    models_all[\"Sklearn-MLP\"] = joblib.load(\"sklearn_mlp.joblib\")\n",
        "# Load PyTorch model\n",
        "models_loaded = {}\n",
        "for name in top2:\n",
        "    if name in models_all:\n",
        "        models_loaded[name] = models_all[name]\n",
        "\n",
        "if os.path.exists(\"pytorch_net_best.pth\"):\n",
        "    pyt_model = SimpleNet(input_dim=X_train_scaled.shape[1])\n",
        "    pyt_model.load_state_dict(torch.load(\"pytorch_net_best.pth\", map_location='cpu'))\n",
        "    pyt_model.eval()\n",
        "    models_loaded[\"PyTorch-Net\"] = pyt_model\n",
        "\n",
        "print(\"Models included in app:\", list(models_loaded.keys()))\n",
        "\n",
        "# Build and run the Dash app with vintage-modern styling\n",
        "import threading\n",
        "from google.colab import output as colab_output\n",
        "\n",
        "# Minimal external stylesheet for font\n",
        "external_stylesheets = [\"https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;600;700&display=swap\"]\n",
        "\n",
        "app = dash.Dash(__name__, external_stylesheets=external_stylesheets, suppress_callback_exceptions=True)\n",
        "\n",
        "# Vintage-modern color scheme\n",
        "BG = \"#f4efe6\"        # soft cream\n",
        "CARD = \"#ffffff\"      # card white\n",
        "ACCENT = \"#6b4f4f\"    # muted brown\n",
        "ACCENT2 = \"#b26500\"   # warm amber\n",
        "TEXT = \"#2b2b2b\"\n",
        "\n",
        "app.layout = html.Div([\n",
        "    html.Link(href=\"https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;600;700&display=swap\", rel=\"stylesheet\"),\n",
        "    html.Div([\n",
        "        html.H2(\"ML Classifier Demo\", style={\"marginBottom\":\"5px\"}),\n",
        "        html.Div(\"Enter 4 features, choose a model, and get a prediction.\", style={\"marginBottom\":\"15px\", \"color\":\"#444\"}),\n",
        "        html.Div([\n",
        "            html.Label(\"Model\", style={\"fontWeight\":\"600\"}),\n",
        "            dcc.Dropdown(\n",
        "                id=\"model-dropdown\",\n",
        "                options=[{\"label\": k, \"value\": k} for k in models_loaded.keys()],\n",
        "                value=list(models_loaded.keys())[0],\n",
        "                clearable=False,\n",
        "                style={\"marginBottom\":\"12px\"}\n",
        "            ),\n",
        "            html.Div([\n",
        "                html.Div([\n",
        "                    html.Label(f\"Feature {i+1}\", style={\"fontSize\":\"14px\", \"fontWeight\":\"500\"}),\n",
        "                    dcc.Input(id=f\"f{i+1}\", type=\"number\", value=0.0, step=0.01, style={\"width\":\"100%\", \"padding\":\"6px\", \"border\":\"1px solid #ccc\", \"borderRadius\":\"4px\"})\n",
        "                ], style={\"padding\":\"6px\", \"width\":\"48%\"}) for i in range(4)\n",
        "            ], style={\"display\":\"flex\", \"flexWrap\":\"wrap\", \"gap\":\"8px\", \"justifyContent\":\"space-between\"}),\n",
        "            html.Button(\"Predict\", id=\"predict-btn\", n_clicks=0,\n",
        "                        style={\"marginTop\":\"12px\", \"backgroundColor\":ACCENT2, \"color\":\"white\", \"border\":\"none\",\n",
        "                               \"padding\":\"10px 18px\", \"borderRadius\":\"6px\", \"fontWeight\":\"600\", \"cursor\":\"pointer\"})\n",
        "        ], style={\"padding\":\"16px\", \"borderRadius\":\"8px\", \"backgroundColor\":CARD, \"boxShadow\":\"0 2px 6px rgba(0,0,0,0.05)\"}),\n",
        "        html.Div(id=\"prediction-output\", style={\"marginTop\":20, \"fontSize\":\"18px\", \"fontWeight\":\"600\", \"color\":ACCENT}),\n",
        "        html.Div(id=\"probability-output\", style={\"marginTop\":8, \"fontSize\":\"16px\", \"color\":TEXT})\n",
        "    ], style={\"maxWidth\":\"720px\", \"margin\":\"20px auto\", \"fontFamily\":\"Montserrat, sans-serif\", \"color\":TEXT})\n",
        "], style={\"minHeight\":\"600px\", \"backgroundColor\":BG, \"padding\":\"20px\"})\n",
        "\n",
        "\n",
        "@app.callback(\n",
        "    [Output(\"prediction-output\", \"children\"),\n",
        "     Output(\"probability-output\", \"children\")],\n",
        "    [Input(\"predict-btn\", \"n_clicks\")],\n",
        "    [State(\"model-dropdown\", \"value\"),\n",
        "     State(\"f1\", \"value\"),\n",
        "     State(\"f2\", \"value\"),\n",
        "     State(\"f3\", \"value\"),\n",
        "     State(\"f4\", \"value\")]\n",
        ")\n",
        "def predict(n_clicks, model_name, f1, f2, f3, f4):\n",
        "    if not n_clicks:\n",
        "        return \"No prediction yet.\", \"\"\n",
        "    x = np.array([[f1, f2, f3, f4]], dtype=float)\n",
        "    x_scaled = scaler.transform(x)\n",
        "\n",
        "    if model_name in [\"LogisticRegression\", \"RandomForest\", \"XGBoost\", \"Sklearn-MLP\"]:\n",
        "        mdl = models_loaded.get(model_name)\n",
        "        proba = float(mdl.predict_proba(x_scaled)[0][1])\n",
        "        pred = int(mdl.predict(x_scaled)[0])\n",
        "    elif model_name == \"PyTorch-Net\":\n",
        "        mdl = models_loaded.get(\"PyTorch-Net\")\n",
        "        with torch.no_grad():\n",
        "            logits = mdl(torch.tensor(x_scaled, dtype=torch.float32))\n",
        "            prob = torch.sigmoid(logits).cpu().numpy()\n",
        "            proba = float(np.array(prob).reshape(-1)[0])\n",
        "            pred = int(proba >= 0.5)\n",
        "    else:\n",
        "        return \"Model not available.\", \"\"\n",
        "    label = \"Yes\" if pred == 1 else \"No\"\n",
        "    return f\"Predicted class: {label}\", f\"Probability(Yes): {proba:.4f}\"\n",
        "\n",
        "\n",
        "# Run the Dash app in a background thread and embed as an iframe inside Colab\n",
        "def _run():\n",
        "    # newest Dash uses app.run(...)\n",
        "    app.run(host=\"0.0.0.0\", port=8050, debug=False)\n",
        "\n",
        "thread = threading.Thread(target=_run, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "# Embed the UI inside the notebook output area\n",
        "from google.colab import output as colab_output\n",
        "colab_output.serve_kernel_port_as_iframe(8050, height=800)"
      ],
      "metadata": {
        "id": "qlCWYPA2gj4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "1yqfXCltptuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kvcK6w1CFzcY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}